{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy\n",
    "from typing import List\n",
    "import math\n",
    "\n",
    "def entropy(class_probabilities: List[float]) -> float:\n",
    "    \"\"\"Given a list of class probabilities, compute the entropy\"\"\"\n",
    "    \n",
    "    return sum(-p * math.log(p, 2) \n",
    "               for p in class_probabilities \n",
    "               if p > 0) # ignore zero probabilities\n",
    "\n",
    "assert entropy([1.0]) == 0\n",
    "assert entropy([0.5, 0.5]) == 1\n",
    "assert 0.81 < entropy([0.25, 0.75]) < 0.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from collections import Counter\n",
    "\n",
    "def class_probabilities(labels: List[Any]) -> List[float]:\n",
    "    total_count = len(labels)\n",
    "    \n",
    "    return [count / total_count \n",
    "            for count in Counter(labels).values()]\n",
    "\n",
    "def data_entropy(labels: List[Any]) -> float:\n",
    "    return entropy(class_probabilities(labels))\n",
    "\n",
    "assert data_entropy(['a']) == 0\n",
    "assert data_entropy([True, False]) == 1\n",
    "assert data_entropy([3, 4, 4, 4]) == entropy([0.25, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy of partition (weighted sum of partition entropy)\n",
    "\n",
    "def partition_entropy(subsets: List[List[Any]]) -> float:\n",
    "    \"\"\"Returns the entropy from this partition of data into subsets\"\"\"\n",
    "    \n",
    "    total_count = sum(len(subset) for subset in subsets)\n",
    "    \n",
    "    return sum(data_entropy(subset) * (len(subset) / total_count) \n",
    "               for subset in subsets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "from typing import NamedTuple, Optional\n",
    "\n",
    "class Candidate(NamedTuple):\n",
    "    level: str\n",
    "    lang: str\n",
    "    tweets: bool\n",
    "    phd: bool\n",
    "    did_well: Optional[bool] = None # allow unlabeled data\n",
    "\n",
    "                 #  level     lang     tweets  phd  did_well\n",
    "inputs = [Candidate('Senior', 'Java',   False, False, False),\n",
    "          Candidate('Senior', 'Java',   False, True,  False),\n",
    "          Candidate('Mid',    'Python', False, False, True),\n",
    "          Candidate('Junior', 'Python', False, False, True),\n",
    "          Candidate('Junior', 'R',      True,  False, True),\n",
    "          Candidate('Junior', 'R',      True,  True,  False),\n",
    "          Candidate('Mid',    'R',      True,  True,  True),\n",
    "          Candidate('Senior', 'Python', False, False, False),\n",
    "          Candidate('Senior', 'R',      True,  False, True),\n",
    "          Candidate('Junior', 'Python', True,  False, True),\n",
    "          Candidate('Senior', 'Python', True,  True,  True),\n",
    "          Candidate('Mid',    'Python', False, True,  True),\n",
    "          Candidate('Mid',    'Java',   True,  False, True),\n",
    "          Candidate('Junior', 'Python', False, True,  False)\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Decision Tree\n",
    "\n",
    "from typing import Dict, TypeVar\n",
    "from collections import defaultdict\n",
    "\n",
    "T = TypeVar('T') # generic type for inputs\n",
    "\n",
    "def partition_by(inputs: List[T], attribute: str) -> Dict[Any, List[T]]:\n",
    "    \"\"\"Partition the inputs into lists based on the specified attribute\"\"\"\n",
    "    \n",
    "    partitions: Dict[Any, List[T]] = defaultdict(list)\n",
    "    \n",
    "    for input in inputs:\n",
    "        key = getattr(input, attribute) # value of the specified attribute\n",
    "        partitions[key].append(input)   # add input to the correct partition\n",
    "    \n",
    "    return partitions\n",
    "\n",
    "def partition_entropy_by(inputs: List[Any], attribute: str, label_attribute: str) -> float:\n",
    "    \"\"\"Compute the entropy corresponding to the given partition\"\"\"\n",
    "    \n",
    "    partitions = partition_by(inputs, attribute) # partitions consist of our inputs\n",
    "    labels = [[getattr(input, label_attribute) for input in partition] # but partition_entropy needs just the class labels \n",
    "              for partition in partitions.values()]\n",
    "    \n",
    "    return partition_entropy(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 0.6935361388961918\n",
      "lang 0.8601317128547441\n",
      "tweets 0.7884504573082896\n",
      "phd 0.8921589282623617\n"
     ]
    }
   ],
   "source": [
    "# Finding the minimum entropy partition\n",
    "\n",
    "for key in ['level', 'lang', 'tweets', 'phd']:\n",
    "    print(key, partition_entropy_by(inputs, key, 'did_well')) # the lowest entropy comes from splitting on 'level'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang 0.4\n",
      "tweets 0.0\n",
      "phd 0.9509775004326937\n"
     ]
    }
   ],
   "source": [
    "# Building a subtree for each possible level value\n",
    "\n",
    "senior_inputs = [input for input in inputs \n",
    "                 if input.level == 'Senior']\n",
    "\n",
    "for key in ['lang', 'tweets', 'phd']:\n",
    "    print(key, partition_entropy_by(senior_inputs, key, 'did_well')) # the lowest entropy comes from splitting on 'tweets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of Decision Tree\n",
    "\n",
    "from typing import NamedTuple, Union, Any\n",
    "\n",
    "class Leaf(NamedTuple):\n",
    "    value: Any\n",
    "        \n",
    "class Split(NamedTuple):\n",
    "    attribute: str\n",
    "    subtrees: dict\n",
    "    default_value: Any = None # handle an unknown value\n",
    "        \n",
    "DecisionTree = Union[Leaf, Split]\n",
    "\n",
    "hiring_tree = Split('level', {   # first, consider 'level'\n",
    "    'Junior': Split('phd', {     # if level is \"Junior\", next look at 'phd' \n",
    "        False: Leaf(True),       # if phd is \"False\", predict True\n",
    "        True: Leaf(False)        # if phd is \"True\", predict False\n",
    "    }),\n",
    "    \n",
    "    'Mid': Leaf(True),           # if level is \"Mid\", just predict True \n",
    "    \n",
    "    'Senior': Split('tweets', {  # if level is \"Senior\", next look at \"tweets\"\n",
    "        False: Leaf(False),      # if tweets is \"False\", predict False\n",
    "        True: Leaf(True)         # if tweets is \"True\", predict True\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree: DecisionTree, input: Any) -> Any:\n",
    "    \"\"\"Classify the input using the given decision tree\"\"\"\n",
    "    \n",
    "    # If this is a leaf node, return its value\n",
    "    if isinstance(tree, Leaf):\n",
    "        return tree.value\n",
    "    \n",
    "    # Otherwise this tree consists of an attribute to split on\n",
    "    # and a dictionary whose keys are values of that attribute\n",
    "    # and whose values are subtrees to consider next\n",
    "    \n",
    "    subtree_key = getattr(input, tree.attribute)\n",
    "    \n",
    "    if subtree_key not in tree.subtrees: # If no subtree for key (e.g., \"Intern\" level)\n",
    "        return tree.default_value        # return the default value \n",
    "    \n",
    "    subtree = tree.subtrees[subtree_key] # Choose an appropriate subtree\n",
    "                                         # and use it to classify the input\n",
    "    \n",
    "    return classify(subtree, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Decision Tree from data\n",
    "\n",
    "def build_tree_id3(inputs: List[Any], \n",
    "                   split_attributes: List[str], \n",
    "                   target_attribute: str) -> DecisionTree:\n",
    "    \n",
    "    # Count target labels\n",
    "    labels_count = Counter(getattr(input, target_attribute) \n",
    "                           for input in inputs)\n",
    "    most_common_label = labels_count.most_common(1)[0][0]\n",
    "    \n",
    "    # If there is a unique label, predict it (no need to learn)\n",
    "    if len(labels_count) == 1:\n",
    "        return Leaf(most_common_label)\n",
    "    \n",
    "    # If no split attributes left, return the majority label\n",
    "    if not split_attributes:\n",
    "        return Leaf(most_common_label)\n",
    "    \n",
    "    # Otherwise split by the best attribute\n",
    "    \n",
    "    def split_entropy(attribute: str) -> float:\n",
    "        \"\"\"Helper function for finding the best attribute to split\"\"\"\n",
    "        \n",
    "        return partition_entropy_by(inputs, attribute, target_attribute)\n",
    "    \n",
    "    best_attribute = min(split_attributes, key=split_entropy)\n",
    "    \n",
    "    partitions = partition_by(inputs, best_attribute)\n",
    "    new_attributes = [a for a in split_attributes \n",
    "                      if a != best_attribute] # eliminate the best attribute we already used\n",
    "    \n",
    "    # Recursively build the subtrees\n",
    "    subtrees = {attribute_value : build_tree_id3(subset, \n",
    "                                                 new_attributes, \n",
    "                                                 target_attribute)\n",
    "               for attribute_value, subset in partitions.items()}\n",
    "    \n",
    "    return Split(best_attribute, subtrees, default_value=most_common_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tree = build_tree_id3(inputs, \n",
    "                      ['level', 'lang', 'tweets', 'phd'], \n",
    "                      'did_well')\n",
    "\n",
    "assert classify(tree, Candidate(\"Junior\", \"Java\", True, False))    # True\n",
    "assert not classify(tree, Candidate(\"Junior\", \"Java\", True, True)) # False\n",
    "assert classify(tree, Candidate(\"Intern\", \"Java\", True, False))    # True (unexpected value \"Intern\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Split(attribute='level', subtrees={'Senior': Split(attribute='tweets', subtrees={False: Leaf(value=False), True: Leaf(value=True)}, default_value=False), 'Mid': Leaf(value=True), 'Junior': Split(attribute='phd', subtrees={False: Leaf(value=True), True: Leaf(value=False)}, default_value=True)}, default_value=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
