{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run ch04_linear_algebra.ipynb\n",
    "%run ch05_statistics.ipynb\n",
    "%run ch08_gradient_descent.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(alpha: float, beta: float, x_i: float) -> float:\n",
    "    return beta * x_i + alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(alpha: float, beta: float, x_i: float, y_i: float) -> float:\n",
    "    return predict(alpha, beta, x_i) - y_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of the squared errors\n",
    "\n",
    "def sum_of_sqerrors(alpha: float, beta: float, x: Vector, y: Vector) -> float:\n",
    "    return sum(error(alpha, beta, x_i, y_i) ** 2 \n",
    "               for x_i, y_i in zip(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Least squares (finding alpha and beta that make the sum of the squared errors as small as possible)\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "def least_squares_fit(x: Vector, y: Vector) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Given two vectors x and y,\n",
    "    find the least-squares values of alpha and beta\n",
    "    \"\"\"\n",
    "    \n",
    "    beta = correlation(x, y) * standard_deviation(y) / standard_deviation(x)\n",
    "    alpha = mean(y) - beta * mean(x)\n",
    "    \n",
    "    return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(-100, 110, 10)]\n",
    "y = [3 * i - 5 for i in x] # y = 3x - 5\n",
    "\n",
    "assert least_squares_fit(x, y) == (-5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, beta = least_squares_fit(num_friends_good, daily_minutes_good)\n",
    "\n",
    "assert 22.9 < alpha < 23.0\n",
    "assert 0.9 < beta < 0.905"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared (measuring the fraction of the total variation in the dependent variable that is captured by the model)\n",
    "\n",
    "def total_sum_of_squares(y: Vector) -> float:\n",
    "    \"\"\"the total squared variation of y_i's from their mean\"\"\"\n",
    "    \n",
    "    return sum(v ** 2 for v in de_mean(y))\n",
    "\n",
    "def r_squared(alpha: float, beta: float, x: Vector, y: Vector) -> float:\n",
    "    \"\"\"\n",
    "    the fraction of variation in y captured by the model, which equals\n",
    "    1 - the fraction of variation in y NOT captured by the model\n",
    "    \"\"\"\n",
    "    \n",
    "    return 1.0 - (sum_of_sqerrors(alpha, beta, x, y) / total_sum_of_squares(y))\n",
    "\n",
    "rsq = r_squared(alpha, beta, num_friends_good, daily_minutes_good)\n",
    "assert 0.328 < rsq < 0.330"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 13196.619: 100%|██████████████████████████████████████████| 10000/10000 [00:20<00:00, 485.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Using gradient descent\n",
    "\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "num_epochs = 10000\n",
    "random.seed(0)\n",
    "\n",
    "guess = [random.random(), random.random()] # random initialization (y = bx + a)\n",
    "learning_rate = 0.00001\n",
    "\n",
    "with tqdm.trange(num_epochs) as t:\n",
    "    for _ in t:\n",
    "        alpha, beta = guess\n",
    "        \n",
    "        # Partial derivative of loss with respect to 'alpha'\n",
    "        grad_a = sum(2 * error(alpha, beta, x_i, y_i) \n",
    "                     for x_i, y_i in zip(num_friends_good, daily_minutes_good))\n",
    "        \n",
    "        # Partial derivative of loss with respect to 'beta'\n",
    "        grad_b = sum(2 * error(alpha, beta, x_i, y_i) * x_i \n",
    "                     for x_i, y_i in zip(num_friends_good, daily_minutes_good))\n",
    "        \n",
    "        # Compute loss to stick in the tqdm description\n",
    "        loss = sum_of_sqerrors(alpha, beta, num_friends_good, daily_minutes_good)\n",
    "        t.set_description(f\"loss: {loss:.3f}\")\n",
    "        \n",
    "        # Finally, update the guess\n",
    "        guess = gradient_step(guess, [grad_a, grad_b], -learning_rate)\n",
    "\n",
    "alpha, beta = guess\n",
    "assert 22.9 < alpha < 23.0\n",
    "assert 0.9 < beta < 0.905"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
